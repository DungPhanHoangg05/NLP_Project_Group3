{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacd6bb5",
   "metadata": {
    "papermill": {
     "duration": 0.005522,
     "end_time": "2025-07-07T07:35:50.650484",
     "exception": false,
     "start_time": "2025-07-07T07:35:50.644962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import libraries and model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c241127",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-07T07:35:50.660176Z",
     "iopub.status.busy": "2025-07-07T07:35:50.659934Z",
     "iopub.status.idle": "2025-07-07T07:35:57.013885Z",
     "shell.execute_reply": "2025-07-07T07:35:57.013186Z"
    },
    "papermill": {
     "duration": 6.360368,
     "end_time": "2025-07-07T07:35:57.015283",
     "exception": false,
     "start_time": "2025-07-07T07:35:50.654915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math, time, os, re, random\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Config\n",
    "MODELNAME = \"NMT_transformer.model\"\n",
    "EPOCH = 20\n",
    "BATCHSIZE = 32\n",
    "LR = 0.0005\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "D_MODEL = 256 \n",
    "NHEAD = 8\n",
    "NUM_ENCODER_LAYERS = 4 \n",
    "NUM_DECODER_LAYERS = 4 \n",
    "DIM_FEEDFORWARD = 1024\n",
    "DROPOUT = 0.1 \n",
    "MAX_SEQ_LENGTH = 100\n",
    "LABEL_SMOOTHING = 0.1\n",
    "WARMUP_STEPS = 4000\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7798ec",
   "metadata": {
    "papermill": {
     "duration": 0.004273,
     "end_time": "2025-07-07T07:35:57.024414",
     "exception": false,
     "start_time": "2025-07-07T07:35:57.020141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98099ce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:35:57.034471Z",
     "iopub.status.busy": "2025-07-07T07:35:57.033808Z",
     "iopub.status.idle": "2025-07-07T07:35:59.534454Z",
     "shell.execute_reply": "2025-07-07T07:35:59.533426Z"
    },
    "papermill": {
     "duration": 2.507183,
     "end_time": "2025-07-07T07:35:59.535976",
     "exception": false,
     "start_time": "2025-07-07T07:35:57.028793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: 133317 training pairs, 1268 test pairs\n"
     ]
    }
   ],
   "source": [
    "def load_file(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return [line.strip().split() for line in f]\n",
    "\n",
    "# Load datasets\n",
    "train_en = load_file(\"./IWSLT/train.en\")\n",
    "train_vi = load_file(\"./IWSLT/train.vi\")\n",
    "test_en  = load_file(\"./IWSLT/test.en\")\n",
    "test_vi  = load_file(\"./IWSLT/test.vi\")\n",
    "\n",
    "print(f\"Data loaded: {len(train_en)} training pairs, {len(test_en)} test pairs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2341c",
   "metadata": {},
   "source": [
    "## Tạo vocab và tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2627d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab EN & VI saved to saved_vocab\n"
     ]
    }
   ],
   "source": [
    "def make_vocab(train_data, min_freq):\n",
    "    vocab = Counter(token for tokens in train_data for token in tokens)\n",
    "    vocablist = [('<unk>', 0), ('<pad>', 0), ('<cls>', 0), ('<eos>', 0)]\n",
    "    vocabidx = {tok: i for i, (tok, _) in enumerate(vocablist)}\n",
    "\n",
    "    for token, freq in vocab.items():\n",
    "        if freq >= min_freq:\n",
    "            idx = len(vocablist)\n",
    "            vocablist.append((token, freq))\n",
    "            vocabidx[token] = idx\n",
    "    return vocablist, vocabidx\n",
    "\n",
    "vocablist_en, vocabidx_en = make_vocab(train_en, 3)\n",
    "vocablist_vi, vocabidx_vi = make_vocab(train_vi, 3)\n",
    "\n",
    "VOCAB_DIR = \"saved_vocab\"\n",
    "\n",
    "os.makedirs(VOCAB_DIR, exist_ok=True)\n",
    "with open(os.path.join(VOCAB_DIR, \"vocab_en.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\"list\": vocablist_en, \"idx\": vocabidx_en}, f)\n",
    "with open(os.path.join(VOCAB_DIR, \"vocab_vi.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\"list\": vocablist_vi, \"idx\": vocabidx_vi}, f)\n",
    "\n",
    "print(f\"Vocab EN & VI saved to {VOCAB_DIR}\")\n",
    "\n",
    "def preprocess(data, vocabidx):\n",
    "    return [['<cls>'] + [tok if tok in vocabidx else '<unk>' for tok in sent] + ['<eos>'] for sent in data]\n",
    "\n",
    "train_en_prep = preprocess(train_en, vocabidx_en)\n",
    "train_vi_prep = preprocess(train_vi, vocabidx_vi)\n",
    "test_en_prep  = preprocess(test_en, vocabidx_en)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb2fef",
   "metadata": {},
   "source": [
    "## Chuẩn bị batch dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5537bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_en_prep, train_vi_prep))\n",
    "train_data.sort(key=lambda x: (len(x[0]), len(x[1])))\n",
    "test_data = list(zip(test_en_prep, test_en, test_vi))\n",
    "\n",
    "def padding_batch(batch):\n",
    "    maxlen = max(len(seq) for seq in batch)\n",
    "    for seq in batch:\n",
    "        seq.extend(['<pad>'] * (maxlen - len(seq)))\n",
    "\n",
    "for ben, bvi in train_data:\n",
    "    padding_batch([ben])\n",
    "    padding_batch([bvi])\n",
    "\n",
    "train_data = [\n",
    "    ([vocabidx_en[t] for t in ben], [vocabidx_vi[t] for t in bvi])\n",
    "    for ben, bvi in train_data\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    ([vocabidx_en[t] for t in enprep], en, vi)\n",
    "    for enprep, en, vi in test_data\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a97a596",
   "metadata": {
    "papermill": {
     "duration": 0.004778,
     "end_time": "2025-07-07T07:36:04.362172",
     "exception": false,
     "start_time": "2025-07-07T07:36:04.357394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Positional encoding và Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c45e52dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:36:04.372911Z",
     "iopub.status.busy": "2025-07-07T07:36:04.372645Z",
     "iopub.status.idle": "2025-07-07T07:36:04.378287Z",
     "shell.execute_reply": "2025-07-07T07:36:04.377630Z"
    },
    "papermill": {
     "duration": 0.012262,
     "end_time": "2025-07-07T07:36:04.379392",
     "exception": false,
     "start_time": "2025-07-07T07:36:04.367130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2], pe[:, 1::2] = torch.sin(position * div_term), torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.pe[:x.size(0)])\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1, ignore_index=None):\n",
    "        super().__init__()\n",
    "        self.confidence, self.smoothing, self.cls, self.dim, self.ignore_index = 1.0 - smoothing, smoothing, classes, dim, ignore_index\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        if self.smoothing == 0:\n",
    "            return F.nll_loss(pred, target, ignore_index=self.ignore_index)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.full_like(pred, self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n",
    "            if self.ignore_index is not None:\n",
    "                true_dist.masked_fill_(target.eq(self.ignore_index).unsqueeze(1), 0)\n",
    "        loss = torch.sum(-true_dist * pred, dim=self.dim)\n",
    "        if self.ignore_index is not None:\n",
    "            non_pad = (~target.eq(self.ignore_index)).sum()\n",
    "            return loss.sum() / non_pad\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab91f77",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "010c632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=256, nhead=8,\n",
    "                 num_encoder_layers=4, num_decoder_layers=4, \n",
    "                 dim_feedforward=1024, dropout=0.1, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.src_embed = nn.Embedding(src_vocab_size, d_model, padding_idx=1)\n",
    "        self.tgt_embed = nn.Embedding(tgt_vocab_size, d_model, padding_idx=1)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len)\n",
    "        enc_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation='gelu', norm_first=True)\n",
    "        dec_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation='gelu', norm_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_encoder_layers)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_decoder_layers)\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1: nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        src = self.pos_encoder(self.src_embed(src) * math.sqrt(self.d_model))\n",
    "        tgt = self.pos_encoder(self.tgt_embed(tgt) * math.sqrt(self.d_model))\n",
    "        memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask, memory_key_padding_mask=src_key_padding_mask)\n",
    "        return self.fc_out(self.layer_norm(output))\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        return torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f94d59",
   "metadata": {},
   "source": [
    "## Warmup Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a477f5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:36:04.445499Z",
     "iopub.status.busy": "2025-07-07T07:36:04.445304Z",
     "iopub.status.idle": "2025-07-07T07:36:04.449726Z",
     "shell.execute_reply": "2025-07-07T07:36:04.449165Z"
    },
    "papermill": {
     "duration": 0.010689,
     "end_time": "2025-07-07T07:36:04.450688",
     "exception": false,
     "start_time": "2025-07-07T07:36:04.439999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WarmupScheduler:\n",
    "    def __init__(self, optimizer, d_model, warmup_steps):\n",
    "        self.optimizer = optimizer\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self._step = 0\n",
    "\n",
    "    def step(self):\n",
    "        self._step += 1\n",
    "        lr = self._get_lr()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = lr\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def _get_lr(self):\n",
    "        return (self.d_model ** -0.5) * min(\n",
    "            self._step ** -0.5,\n",
    "            self._step * (self.warmup_steps ** -1.5)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d913653f",
   "metadata": {
    "papermill": {
     "duration": 0.004587,
     "end_time": "2025-07-07T07:36:04.460595",
     "exception": false,
     "start_time": "2025-07-07T07:36:04.456008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tính BLEU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a772ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:36:04.470760Z",
     "iopub.status.busy": "2025-07-07T07:36:04.470537Z",
     "iopub.status.idle": "2025-07-07T07:36:04.474500Z",
     "shell.execute_reply": "2025-07-07T07:36:04.473976Z"
    },
    "papermill": {
     "duration": 0.010502,
     "end_time": "2025-07-07T07:36:04.475801",
     "exception": false,
     "start_time": "2025-07-07T07:36:04.465299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_bleu(model, test_data, vocabidx_en, vocabidx_vi, vocablist_vi, max_len=50):\n",
    "    model.eval()\n",
    "    predictions, references = [], []\n",
    "    inv_vocab_vi = {i: t for i, (t, _) in enumerate(vocablist_vi)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for en_idx, en_tokens, vi_tokens in tqdm(test_data, desc=\"Evaluating BLEU\"):\n",
    "            src = torch.tensor(en_idx).unsqueeze(1).to(DEVICE)\n",
    "            src_mask = None\n",
    "            src_key_padding_mask = src.eq(vocabidx_en['<pad>']).T\n",
    "\n",
    "            memory = model.encoder(model.pos_encoder(model.src_embed(src) * math.sqrt(model.d_model)),\n",
    "                                   mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "            tgt_tokens = [vocabidx_vi['<cls>']]\n",
    "            for _ in range(max_len):\n",
    "                tgt = torch.tensor(tgt_tokens).unsqueeze(1).to(DEVICE)\n",
    "                tgt_mask = model.generate_square_subsequent_mask(tgt.size(0)).to(DEVICE)\n",
    "                out = model.decoder(model.pos_encoder(model.tgt_embed(tgt) * math.sqrt(model.d_model)),\n",
    "                                    memory, tgt_mask=tgt_mask,\n",
    "                                    memory_key_padding_mask=src_key_padding_mask)\n",
    "                prob = model.fc_out(model.layer_norm(out))\n",
    "                next_token = prob[-1].argmax(dim=-1).item()\n",
    "                tgt_tokens.append(next_token)\n",
    "                if next_token == vocabidx_vi['<eos>']:\n",
    "                    break\n",
    "\n",
    "            pred_sentence = [inv_vocab_vi[idx] for idx in tgt_tokens[1:-1]]\n",
    "            predictions.append(pred_sentence)\n",
    "            references.append([vi_tokens])\n",
    "\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    bleu = corpus_bleu(references, predictions, smoothing_function=smoothie)\n",
    "    return bleu, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d492f32",
   "metadata": {
    "papermill": {
     "duration": 0.004848,
     "end_time": "2025-07-07T07:36:04.529438",
     "exception": false,
     "start_time": "2025-07-07T07:36:04.524590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3bf73973",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T07:36:04.539987Z",
     "iopub.status.busy": "2025-07-07T07:36:04.539635Z",
     "iopub.status.idle": "2025-07-07T07:36:09.493909Z",
     "shell.execute_reply": "2025-07-07T07:36:09.493313Z"
    },
    "papermill": {
     "duration": 4.961318,
     "end_time": "2025-07-07T07:36:09.495284",
     "exception": false,
     "start_time": "2025-07-07T07:36:04.533966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch, pad_idx_src, pad_idx_tgt):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src, tgt in batch:\n",
    "        src_batch.append(torch.tensor(src, dtype=torch.long))\n",
    "        tgt_batch.append(torch.tensor(tgt, dtype=torch.long))\n",
    "    src_batch = pad_sequence(src_batch, padding_value=pad_idx_src)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=pad_idx_tgt)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_data, test_data, optimizer, scheduler, criterion, epochs):\n",
    "    best_bleu = 0.0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        random.shuffle(train_data)\n",
    "\n",
    "        for i in tqdm(range(0, len(train_data), BATCHSIZE), desc=f\"Epoch {epoch}\"):\n",
    "            batch = train_data[i:i+BATCHSIZE]\n",
    "            src_batch, tgt_batch = collate_batch(\n",
    "                batch, vocabidx_en['<pad>'], vocabidx_vi['<pad>']\n",
    "            )\n",
    "\n",
    "            src_batch, tgt_batch = src_batch.to(DEVICE), tgt_batch.to(DEVICE)\n",
    "            tgt_input = tgt_batch[:-1, :]\n",
    "            tgt_output = tgt_batch[1:, :]\n",
    "\n",
    "            src_mask = None\n",
    "            tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(0)).to(DEVICE)\n",
    "\n",
    "            src_key_padding_mask = src_batch.eq(vocabidx_en['<pad>']).T\n",
    "            tgt_key_padding_mask = tgt_input.eq(vocabidx_vi['<pad>']).T\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src_batch, tgt_input, src_mask, tgt_mask,\n",
    "                           src_key_padding_mask, tgt_key_padding_mask)\n",
    "            output = output.reshape(-1, output.size(-1))\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, tgt_output)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / (len(train_data) / BATCHSIZE)\n",
    "        bleu, _ = evaluate_bleu(model, test_data, vocabidx_en, vocabidx_vi, vocablist_vi)\n",
    "        print(f\"Epoch {epoch}: Loss={avg_loss:.4f}, BLEU={bleu*100:.2f}\")\n",
    "\n",
    "        if bleu > best_bleu:\n",
    "            best_bleu = bleu\n",
    "            torch.save({\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"config\": {\n",
    "                    \"src_vocab_size\": len(vocablist_en),\n",
    "                    \"tgt_vocab_size\": len(vocablist_vi),\n",
    "                    \"d_model\": D_MODEL,\n",
    "                    \"nhead\": NHEAD,\n",
    "                    \"num_encoder_layers\": NUM_ENCODER_LAYERS,\n",
    "                    \"num_decoder_layers\": NUM_DECODER_LAYERS,\n",
    "                    \"dim_feedforward\": DIM_FEEDFORWARD,\n",
    "                    \"dropout\": DROPOUT\n",
    "                }\n",
    "            }, MODELNAME)\n",
    "            print(f\"New best BLEU: {best_bleu*100:.2f}, best model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f06963",
   "metadata": {
    "papermill": {
     "duration": 24.748961,
     "end_time": "2025-07-07T11:55:08.374972",
     "exception": false,
     "start_time": "2025-07-07T11:54:43.626011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Khởi tạo mô hình và Huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e969ac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Legion\\anaconda3\\envs\\nlp_proj\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(len(vocablist_en), len(vocablist_vi), D_MODEL, NHEAD,\n",
    "                    NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                    DIM_FEEDFORWARD, DROPOUT).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c336c5ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:55:58.077986Z",
     "iopub.status.busy": "2025-07-07T11:55:58.077659Z",
     "iopub.status.idle": "2025-07-07T12:13:55.623034Z",
     "shell.execute_reply": "2025-07-07T12:13:55.622263Z"
    },
    "papermill": {
     "duration": 1104.662447,
     "end_time": "2025-07-07T12:13:58.154805",
     "exception": false,
     "start_time": "2025-07-07T11:55:33.492358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4167/4167 [08:52<00:00,  7.83it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [01:58<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=5.2593, BLEU=13.17\n",
      "New best BLEU: 13.17, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4167/4167 [08:37<00:00,  8.06it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:03<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=3.8291, BLEU=20.74\n",
      "New best BLEU: 20.74, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4167/4167 [08:36<00:00,  8.06it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:00<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=3.4488, BLEU=22.92\n",
      "New best BLEU: 22.92, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 4167/4167 [09:02<00:00,  7.68it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:07<00:00,  9.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=3.2710, BLEU=24.12\n",
      "New best BLEU: 24.12, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 4167/4167 [09:13<00:00,  7.53it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:09<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=3.1579, BLEU=25.05\n",
      "New best BLEU: 25.05, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 4167/4167 [09:14<00:00,  7.52it/s] \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:13<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=3.0777, BLEU=25.38\n",
      "New best BLEU: 25.38, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 4167/4167 [09:13<00:00,  7.53it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:14<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=3.0141, BLEU=25.79\n",
      "New best BLEU: 25.79, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 4167/4167 [09:11<00:00,  7.56it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:11<00:00,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=2.9643, BLEU=25.87\n",
      "New best BLEU: 25.87, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 4167/4167 [09:13<00:00,  7.53it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:09<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=2.9214, BLEU=25.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 4167/4167 [09:12<00:00,  7.54it/s] \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:13<00:00,  9.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=2.8834, BLEU=26.38\n",
      "New best BLEU: 26.38, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 4167/4167 [09:13<00:00,  7.53it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:10<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=2.8519, BLEU=26.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 4167/4167 [09:13<00:00,  7.53it/s] \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:12<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=2.8237, BLEU=26.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 4167/4167 [09:14<00:00,  7.51it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:10<00:00,  9.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=2.7981, BLEU=26.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 4167/4167 [09:11<00:00,  7.55it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:15<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=2.7743, BLEU=26.46\n",
      "New best BLEU: 26.46, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 4167/4167 [09:11<00:00,  7.55it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:13<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=2.7523, BLEU=26.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 4167/4167 [09:13<00:00,  7.53it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:16<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=2.7322, BLEU=26.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 4167/4167 [09:12<00:00,  7.54it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:13<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=2.7138, BLEU=26.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 4167/4167 [09:11<00:00,  7.55it/s]  \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:13<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=2.6971, BLEU=26.48\n",
      "New best BLEU: 26.48, best model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 4167/4167 [09:13<00:00,  7.52it/s] \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:09<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=2.6812, BLEU=25.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 4167/4167 [09:12<00:00,  7.54it/s] \n",
      "Evaluating BLEU: 100%|██████████| 1268/1268 [02:08<00:00,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=2.6652, BLEU=26.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = WarmupScheduler(optimizer, D_MODEL, WARMUP_STEPS)\n",
    "criterion = LabelSmoothingLoss(len(vocablist_vi), smoothing=LABEL_SMOOTHING,\n",
    "                               ignore_index=vocabidx_vi['<pad>'])\n",
    "\n",
    "train_model(model, train_data, test_data, optimizer, scheduler, criterion, EPOCH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c901662",
   "metadata": {},
   "source": [
    "## Kết quả cuối cùng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2161d0",
   "metadata": {},
   "source": [
    "#### Kết quả BLEU score trên tập IWSLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BLEU: 100%|██████████| 1268/1268 [01:52<00:00, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU Score: 26.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"NMT_transformer.model\")\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "bleu, predictions = evaluate_bleu(model, test_data, vocabidx_en, vocabidx_vi, vocablist_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9603734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU Score on IWSLT data: 26.48\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final BLEU Score on IWSLT data: {bleu*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8174864",
   "metadata": {},
   "source": [
    "#### Kết quả BLEU score trên tập data của thầy để so sánh với mô hình sau finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90eb6844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000 new test pairs for evaluation.\n"
     ]
    }
   ],
   "source": [
    "test_en_path  = \"./Released Corpus/test.en.txt\"\n",
    "test_vi_path  = \"./Released Corpus/test.vi.txt\"\n",
    "\n",
    "test_en_new  = load_file(test_en_path)\n",
    "test_vi_new  = load_file(test_vi_path)\n",
    "\n",
    "test_en_prep_new  = preprocess(test_en_new, vocabidx_en)\n",
    "test_vi_prep_new  = preprocess(test_vi_new, vocabidx_vi)\n",
    "\n",
    "test_data_new = [\n",
    "    (\n",
    "        [vocabidx_en[token] for token in en_tokens],\n",
    "        en_original,\n",
    "        vi_original\n",
    "    )\n",
    "    for en_tokens, en_original, vi_original in zip(test_en_prep_new, test_en_new, test_vi_new)\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(test_data_new)} new test pairs for evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d9420cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BLEU: 100%|██████████| 3000/3000 [05:14<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final BLEU Score on Released Corpus data: 8.49\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['model_state'])\n",
    "bleu, predictions = evaluate_bleu(model, test_data_new, vocabidx_en, vocabidx_vi, vocablist_vi)\n",
    "print(f\"Final BLEU Score on Released Corpus data: {bleu*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16828.807423,
   "end_time": "2025-07-07T12:16:15.193340",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T07:35:46.385917",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
