{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908039df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "from pyvi import ViTokenizer\n",
    "import spacy\n",
    "import itertools\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3110a",
   "metadata": {},
   "source": [
    "#### Tạo tokenizer cho English và Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75583aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text.lower() for tok in spacy_en.tokenizer(text.strip())]\n",
    "\n",
    "def tokenize_vi(text):\n",
    "    return ViTokenizer.tokenize(text.strip().lower()).split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b9014",
   "metadata": {},
   "source": [
    "#### Build vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f10cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, min_freq=2, specials=[\"<pad>\", \"<unk>\"]):\n",
    "    counter = Counter(itertools.chain(*sentences))\n",
    "    vocab = {tok: idx for idx, tok in enumerate(specials)}\n",
    "    idx = len(vocab)\n",
    "    for token, freq in counter.items():\n",
    "        if freq >= min_freq and token not in vocab:\n",
    "            vocab[token] = idx\n",
    "            idx += 1\n",
    "    vocab['itos'] = {i: s for s, i in vocab.items()}\n",
    "    return vocab\n",
    "\n",
    "def encode(sentence, vocab):\n",
    "    return [vocab.get(tok, vocab[\"<unk>\"]) for tok in sentence]\n",
    "\n",
    "def decode(indices, vocab):\n",
    "    return [vocab['itos'][idx] for idx in indices if idx in vocab['itos']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bda1c6",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df0b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_file, tgt_file, src_tokenizer, tgt_tokenizer):\n",
    "        with open(src_file, 'r', encoding='utf-8') as f:\n",
    "            self.src_sentences = f.readlines()\n",
    "        with open(tgt_file, 'r', encoding='utf-8') as f:\n",
    "            self.tgt_sentences = f.readlines()\n",
    "\n",
    "        assert len(self.src_sentences) == len(self.tgt_sentences)\n",
    "\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "        self.src_tokens = [self.src_tokenizer(s) for s in self.src_sentences]\n",
    "        self.tgt_tokens = [[\"<bos>\"] + self.tgt_tokenizer(s) + [\"<eos>\"] for s in self.tgt_sentences]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.src_tokens[idx], self.tgt_tokens[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f1747c",
   "metadata": {},
   "source": [
    "#### Collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de93e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, src_vocab, tgt_vocab):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "\n",
    "    src_indices = [torch.tensor(encode(sent, src_vocab), dtype=torch.long) for sent in src_batch]\n",
    "    tgt_indices = [torch.tensor(encode(sent, tgt_vocab), dtype=torch.long) for sent in tgt_batch]\n",
    "\n",
    "    src_batch_padded = pad_sequence(src_indices, padding_value=src_vocab[\"<pad>\"], batch_first=True)\n",
    "    tgt_batch_padded = pad_sequence(tgt_indices, padding_value=tgt_vocab[\"<pad>\"], batch_first=True)\n",
    "\n",
    "    return src_batch_padded, tgt_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = \"../Released Corpus/train.en.txt\" \n",
    "tgt_file = \"../Released Corpus/train.vi.txt\"\n",
    "\n",
    "train_dataset = TranslationDataset(src_file, tgt_file, tokenize_en, tokenize_vi)\n",
    "\n",
    "src_token_lists = train_dataset.src_tokens\n",
    "tgt_token_lists = train_dataset.tgt_tokens\n",
    "\n",
    "src_vocab = build_vocab(src_token_lists)\n",
    "tgt_vocab = build_vocab(tgt_token_lists, specials=[\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda batch: collate_fn(batch, src_vocab, tgt_vocab)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9307a1",
   "metadata": {},
   "source": [
    "# Cài đặt Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa282d64",
   "metadata": {},
   "source": [
    "#### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66ea6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.pe = pe.unsqueeze(0)  # shape (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1)].to(x.device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25dde5e",
   "metadata": {},
   "source": [
    "#### Scaled-dot Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a89591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size(-1)\n",
    "    scores = q @ k.transpose(-2, -1) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    attn = F.softmax(scores, dim=-1)\n",
    "    return attn @ v, attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8100fb1",
   "metadata": {},
   "source": [
    "#### Multi-Head Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d382a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.linear_q = nn.Linear(d_model, d_model)\n",
    "        self.linear_k = nn.Linear(d_model, d_model)\n",
    "        self.linear_v = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        B, L_q, _ = q.shape\n",
    "        B, L_k, _ = k.shape\n",
    "        B, L_v, _ = v.shape\n",
    "\n",
    "\n",
    "        q = self.linear_q(q).view(B, L_q, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.linear_k(k).view(B, L_k, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.linear_v(v).view(B, L_v, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float(\"-inf\"))\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)  # (B, heads, L_q, d_k)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, L_q, self.d_model)\n",
    "        return self.out_proj(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15366549",
   "metadata": {},
   "source": [
    "#### Feed-Forward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c872f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931279fa",
   "metadata": {},
   "source": [
    "#### Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97c2b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out = self.attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_out))\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff_out))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051b5d8",
   "metadata": {},
   "source": [
    "#### Decoder Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb2d48d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n",
    "        x2 = self.norm1(x + self.dropout(self.self_attn(x, x, x, tgt_mask)))\n",
    "        x2 = self.norm2(x2 + self.dropout(self.enc_attn(x2, enc_out, enc_out, src_mask)))\n",
    "        x2 = self.norm3(x2 + self.dropout(self.ff(x2)))\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c1ab4",
   "metadata": {},
   "source": [
    "#### Encoder & Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4c29ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(N)])\n",
    "\n",
    "    def forward(self, src, mask=None):\n",
    "        x = self.embed(src)\n",
    "        x = self.pos_enc(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(N)])\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, tgt, enc_out, src_mask=None, tgt_mask=None):\n",
    "        x = self.embed(tgt)\n",
    "        x = self.pos_enc(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, src_mask, tgt_mask)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8e6b5",
   "metadata": {},
   "source": [
    "#### Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0f58083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, N=6, num_heads=8, d_ff=2048, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, N, num_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, N, num_heads, d_ff, dropout)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        out = self.decoder(tgt, enc_out, src_mask, tgt_mask)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328200ec",
   "metadata": {},
   "source": [
    "# Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd006af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
    "    return mask == 0  # True là vị trí hợp lệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7425adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer_and_loss(model, tgt_pad_idx, lr=1e-4):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_pad_idx)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "    return optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0c5a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, tgt_pad_idx, device, num_epochs=10, print_every=100):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for i, (src, tgt) in enumerate(dataloader):\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "\n",
    "            src_mask = None\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n",
    "\n",
    "            logits = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            logits = logits.reshape(-1, logits.size(-1))\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "\n",
    "            loss = criterion(logits, tgt_output)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % print_every == 0:\n",
    "                print(f\"Epoch {epoch+1}, Step {i+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Average Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n",
    "def save_model(model, path=\"transformer_nmt.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8c8b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5183c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình\n",
    "model = Transformer(\n",
    "    src_vocab_size=len(src_vocab),\n",
    "    tgt_vocab_size=len(tgt_vocab),\n",
    "    d_model=256,         \n",
    "    N=3,                 \n",
    "    num_heads=4,\n",
    "    d_ff=1024,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "optimizer, criterion = create_optimizer_and_loss(model, tgt_pad_idx=tgt_vocab[\"<pad>\"])\n",
    "\n",
    "train_model(model, train_loader, optimizer, criterion, tgt_pad_idx=tgt_vocab[\"<pad>\"], device=device, num_epochs=8)\n",
    "\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ec8633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decode(model, src, src_vocab, tgt_vocab, beam_size=5, max_len=50, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src = src.unsqueeze(0).to(device)  # (1, src_len)\n",
    "        src_mask = None\n",
    "        enc_out = model.encoder(src, src_mask)\n",
    "\n",
    "        # Mỗi phần tử beam: (tgt_indices, log_prob)\n",
    "        beams = [([tgt_vocab[\"<bos>\"]], 0.0)]\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            new_beams = []\n",
    "            for seq, score in beams:\n",
    "                if seq[-1] == tgt_vocab[\"<eos>\"]:\n",
    "                    new_beams.append((seq, score))\n",
    "                    continue\n",
    "\n",
    "                tgt_tensor = torch.tensor(seq, dtype=torch.long).unsqueeze(0).to(device)\n",
    "                tgt_mask = generate_square_subsequent_mask(tgt_tensor.size(1)).to(device)\n",
    "\n",
    "                output = model.decoder(tgt_tensor, enc_out, src_mask, tgt_mask)\n",
    "                output = output[:, -1, :]  # Lấy logit của token cuối\n",
    "                probs = torch.log_softmax(output, dim=-1)\n",
    "\n",
    "                topk_probs, topk_ids = probs.topk(beam_size)\n",
    "\n",
    "                for i in range(beam_size):\n",
    "                    next_seq = seq + [topk_ids[0, i].item()]\n",
    "                    next_score = score + topk_probs[0, i].item()\n",
    "                    new_beams.append((next_seq, next_score))\n",
    "\n",
    "            # Giữ lại beam_size chuỗi tốt nhất\n",
    "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "\n",
    "        # Chọn chuỗi có score cao nhất\n",
    "        best_seq = beams[0][0]\n",
    "\n",
    "        # Bỏ <bos> và <eos>\n",
    "        return decode([idx for idx in best_seq if idx not in {tgt_vocab[\"<bos>\"], tgt_vocab[\"<eos>\"]}], tgt_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89435f16",
   "metadata": {},
   "source": [
    "# Kết quả BLEU score cuối cùng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0939bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    src_vocab_size=len(src_vocab),\n",
    "    tgt_vocab_size=len(tgt_vocab),\n",
    "    d_model=256,\n",
    "    N=3,\n",
    "    num_heads=4,\n",
    "    d_ff=1024,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"transformer_nmt.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = TranslationDataset(\n",
    "    src_file=\"../Released Corpus/test.en.txt\",\n",
    "    tgt_file=\"../Released Corpus/test.vi.txt\",\n",
    "    src_tokenizer=tokenize_en,\n",
    "    tgt_tokenizer=tokenize_vi\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda batch: collate_fn(batch, src_vocab, tgt_vocab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3121f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test BLEU score: 26.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "refs = []\n",
    "hyps = []\n",
    "\n",
    "for src_batch, tgt_batch in test_loader:\n",
    "    src_tokens = src_batch[0]\n",
    "    tgt_tokens = tgt_batch[0]\n",
    "\n",
    "    tgt_text = decode([idx.item() for idx in tgt_tokens if idx.item() not in {\n",
    "        tgt_vocab[\"<pad>\"], tgt_vocab[\"<bos>\"], tgt_vocab[\"<eos>\"]\n",
    "    }], tgt_vocab)\n",
    "    refs.append([tgt_text])\n",
    "\n",
    "    pred_tokens = beam_search_decode(model, src_tokens, src_vocab, tgt_vocab, max_len=50, device=device)\n",
    "    hyps.append(pred_tokens)\n",
    "\n",
    "smoothie = SmoothingFunction().method4\n",
    "bleu_score = corpus_bleu(refs, hyps, smoothing_function=smoothie)\n",
    "\n",
    "print(f\"Test BLEU score: {bleu_score*100:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
