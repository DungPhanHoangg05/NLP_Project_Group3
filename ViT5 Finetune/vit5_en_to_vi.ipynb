{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e62661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Legion\\anaconda3\\envs\\nlp_proj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3a8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTokenizedDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_mask, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Hàm chuẩn bị dữ liệu (tokenize toàn bộ trước)\n",
    "def prepare_data(vi_file, en_file, tokenizer, max_length=256):\n",
    "    with open(vi_file, 'r', encoding='utf-8') as f:\n",
    "        vi_texts = [line.strip() for line in f]\n",
    "    with open(en_file, 'r', encoding='utf-8') as f:\n",
    "        en_texts = [line.strip() for line in f]\n",
    "\n",
    "    assert len(vi_texts) == len(en_texts), \"Số lượng câu không khớp!\"\n",
    "\n",
    "    # Thêm prefix cho input\n",
    "    src_texts = [f\"en-vi: {en}\" for en in en_texts]\n",
    "    \n",
    "    # Tokenize source\n",
    "    src_enc = tokenizer(\n",
    "        src_texts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize target\n",
    "    tgt_enc = tokenizer(\n",
    "        vi_texts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    labels = tgt_enc[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "    return PreTokenizedDataset(src_enc[\"input_ids\"], src_enc[\"attention_mask\"], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791f304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        # Di chuyển data lên GPU\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa813edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_bleu(model, dataloader, tokenizer, device, max_samples=None):\n",
    "    \"\"\"Tính BLEU score cho model trên dataset bằng SacreBLEU\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    references = []\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(dataloader, desc=\"Evaluating BLEU\")):\n",
    "            if max_samples and i >= max_samples:\n",
    "                break\n",
    "                \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Tính loss\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            total_loss += outputs.loss.item()\n",
    "            \n",
    "            # Generate predictions\n",
    "            generated = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                max_length=512,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                do_sample=False\n",
    "            )\n",
    "            \n",
    "            # Decode predictions và references\n",
    "            for j in range(len(generated)):\n",
    "                # Decode prediction\n",
    "                pred = tokenizer.decode(generated[j], skip_special_tokens=True)\n",
    "                predictions.append(pred)\n",
    "                \n",
    "                # Decode reference (target)\n",
    "                label = labels[j].cpu().numpy()\n",
    "                label[label == -100] = tokenizer.pad_token_id\n",
    "                ref = tokenizer.decode(label, skip_special_tokens=True)\n",
    "                references.append(ref)\n",
    "    \n",
    "    # Tính BLEU score bằng SacreBLEU\n",
    "    bleu = sacrebleu.corpus_bleu(predictions, [references])\n",
    "    bleu_score = bleu.score \n",
    "    \n",
    "    avg_loss = total_loss / min(len(dataloader), max_samples or len(dataloader))\n",
    "    \n",
    "    return avg_loss, bleu_score, predictions[:5], references[:5]  # Return 5 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838f884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 62500\n",
      "Training samples: 500000\n",
      "Test samples: 3000\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 62500/62500 [4:46:53<00:00,  3.63it/s, loss=1.38]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.3419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BLEU:  27%|██▋       | 100/375 [02:03<05:40,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8780\n",
      "BLEU Score: 50.2220 (5022.2)\n",
      "\n",
      "Sample translations:\n",
      "Pred: Kiến thức, thực hành sử dụng dịch vụ y tế công cộng của người bảo hiểm y tế và các yếu tố ảnh hưởng tại Lào, Lào\n",
      "Ref:  Thực trạng kiến thức và thực hành của người có thẻ bảo hiểm y tế trong sử dụng dịch vụ khám chữa bệnh ở các cơ sở y tế công và một số yếu tố ảnh hưởng tại tỉnh Viêng Chăn, CHDCND Lào, năm 2017\n",
      "\n",
      "Pred: Mô tả kiến thức, thực hành sử dụng dịch vụ y tế công cộng của người giữ thẻ bảo hiểm y tế và các yếu tố ảnh hưởng tại Vientiane, Lào PDR, năm 2017.\n",
      "Ref:  Mô tả thực trạng kiến thức, thực hành của người có thẻ bảo hiểm y tế trong sử dụng dịch vụ khám chữa bệnh ở các cơ sở y tế công và một số yếu tố liên quan tại tỉnh Viêng Chăn, Cộng hoà Dân chủ Nhân dân Lào năm 2017.\n",
      "\n",
      "Pred: Đối tượng và phương pháp nghiên cứu: Nghiên cứu mô tả cắt ngang được thực hiện trên 928 người giữ thẻ bảo hiểm y tế người trưởng thành tại huyện Điện Biên và huyện Keo Oudom, tỉnh Lào Cai.\n",
      "Ref:  Phương pháp: Thiết kế nghiên mô tả cắt ngang được thực hiện trên 928 người trưởng thành có thẻ bảo hiểm y tế tại 2 huyện Phone Hong và Keo Oudom, tỉnh Viêng Chăn.\n",
      "\n",
      "New best BLEU score! Saving model...\n",
      "\n",
      "Training completed!\n",
      "Best BLEU Score: 50.2220\n",
      "Model saved to: ./vit5_finetuned\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"VietAI/vit5-base\"  \n",
    "BATCH_SIZE = 8      \n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 1\n",
    "MAX_LENGTH = 128\n",
    "OUTPUT_DIR = \"./vit5_finetuned_en_to_vi\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer và model\n",
    "print(\"Loading tokenizer and model...\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "model.to(device)\n",
    "\n",
    "# Tạo datasets\n",
    "train_dataset = prepare_data(\"Released Corpus/train.vi.txt\", \"Released Corpus/train.en.txt\", tokenizer, MAX_LENGTH)\n",
    "test_dataset = prepare_data(\"Released Corpus/test.vi.txt\", \"Released Corpus/test.en.txt\", tokenizer, MAX_LENGTH)\n",
    "\n",
    "# Tạo dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Optimizer và scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "total_steps = len(train_dataloader) * NUM_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print(f\"Total training steps: {total_steps}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "best_bleu = 0\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Evaluate với BLEU score (giới hạn số samples để tăng tốc)\n",
    "    val_loss, bleu_score, sample_preds, sample_refs = evaluate_bleu(\n",
    "        model, test_dataloader, tokenizer, device, max_samples=100\n",
    "    )\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    print(f\"BLEU Score: {bleu_score:.4f} ({bleu_score*100:.1f})\")  \n",
    "    \n",
    "    # Hiển thị một số ví dụ dịch\n",
    "    print(\"\\nSample translations:\")\n",
    "    for i in range(min(3, len(sample_preds))):\n",
    "        print(f\"Pred: {sample_preds[i]}\")\n",
    "        print(f\"Ref:  {sample_refs[i]}\")\n",
    "        print()\n",
    "    \n",
    "    # Save best model dựa trên BLEU score\n",
    "    if bleu_score > best_bleu:\n",
    "        best_bleu = bleu_score\n",
    "        best_val_loss = val_loss\n",
    "        print(\"New best BLEU score! Saving model...\")\n",
    "        \n",
    "        if not os.path.exists(OUTPUT_DIR):\n",
    "            os.makedirs(OUTPUT_DIR)\n",
    "            \n",
    "        model.save_pretrained(OUTPUT_DIR)\n",
    "        tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "        \n",
    "        # Save thông tin về best score\n",
    "        with open(os.path.join(OUTPUT_DIR, \"training_info.txt\"), \"w\") as f:\n",
    "            f.write(f\"Best BLEU Score: {best_bleu:.4f}\\n\")\n",
    "            f.write(f\"Best Epoch: {epoch + 1}\\n\")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best BLEU Score: {best_bleu:.4f}\")\n",
    "print(f\"Model saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca493c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_test_evaluation(model_path, test_vi_file, test_en_file):\n",
    "    \"\"\"Đánh giá cuối cùng trên toàn bộ tập test bằng SacreBLEU\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(\"FINAL EVALUATION ON FULL TEST SET\")\n",
    "    \n",
    "    # Load model và tokenizer\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Load test data\n",
    "    with open(test_en_file, 'r', encoding='utf-8') as f:\n",
    "        test_en_texts = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "    with open(test_vi_file, 'r', encoding='utf-8') as f:\n",
    "        test_vi_texts = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    predictions = []\n",
    "    references = test_vi_texts\n",
    "    \n",
    "    print(f\"Translating {len(test_en_texts)} test sentences...\")\n",
    "    \n",
    "    for i, en_text in enumerate(tqdm(test_en_texts, desc=\"Translating\")):\n",
    "        # Thêm prefix\n",
    "        input_text = f\"en-vi: {en_text}\"\n",
    "        \n",
    "        # Tokenize\n",
    "        inputs = tokenizer(\n",
    "            input_text,\n",
    "            return_tensors='pt',\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_length=512,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        # Decode\n",
    "        translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        predictions.append(translation)\n",
    "    \n",
    "    # Tính BLEU score bằng SacreBLEU\n",
    "    bleu = sacrebleu.corpus_bleu(predictions, [references])\n",
    "    \n",
    "    print(\"FINAL TEST RESULTS:\")\n",
    "    print(f\"Total test samples: {len(test_en_texts)}\")\n",
    "    print(f\"BLEU Score: {bleu.score:.2f}\")\n",
    "    print(f\"BLEU Details: {bleu}\")\n",
    "    \n",
    "    # Save kết quả\n",
    "    results_file = os.path.join(model_path, \"final_test_results.txt\")\n",
    "    with open(results_file, \"w\", encoding='utf-8') as f:\n",
    "        f.write(f\"Final Test Results\\n\")\n",
    "        f.write(f\"Total test samples: {len(test_en_texts)}\\n\")\n",
    "        f.write(f\"BLEU Score: {bleu.score:.2f}\\n\")\n",
    "        f.write(f\"BLEU Details: {bleu}\\n\")\n",
    "        for i in range(min(10, len(predictions))):\n",
    "            f.write(f\"\\nExample {i+1}:\\n\")\n",
    "            f.write(f\"EN: {test_en_texts[i]}\\n\")\n",
    "            f.write(f\"Pred: {predictions[i]}\\n\")\n",
    "            f.write(f\"Ref: {references[i]}\\n\")\n",
    "    \n",
    "    print(f\"Detailed results saved to: {results_file}\")\n",
    "    \n",
    "    return bleu.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9da7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL EVALUATION ON FULL TEST SET\n",
      "Translating 3000 test sentences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating: 100%|██████████| 3000/3000 [24:52<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL TEST RESULTS:\n",
      "Total test samples: 3000\n",
      "BLEU Score: 47.11\n",
      "BLEU Details: BLEU = 47.11 75.2/56.4/43.3/33.9 (BP = 0.943 ratio = 0.945 hyp_len = 95273 ref_len = 100870)\n",
      "Detailed results saved to: ./vit5_finetuned\\final_test_results.txt\n",
      "\n",
      "Final BLEU-4 score on full test set: 47.1097\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation trên toàn bộ test set\n",
    "if os.path.exists(\"./vit5_finetuned_en_to_vi\"):\n",
    "    final_bleu = final_test_evaluation(\"./vit5_finetuned_en_to_vi\", \"Released Corpus/test.vi.txt\", \"Released Corpus/test.en.txt\")\n",
    "    print(f\"\\nFinal BLEU-4 score on full test set: {final_bleu:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
